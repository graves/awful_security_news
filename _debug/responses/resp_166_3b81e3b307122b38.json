{
  "category": "Science & Technology",
  "dateOfPublication": "2025-10-06",
  "importantDates": [
    {
      "dateMentionedInArticle": "2025-02-04",
      "descriptionOfWhyDateIsRelevant": "The date of the fake phone call from a deepfake voice of Defence Minister Guido Crosetto, which led to a scam targeting Italian businessmen."
    },
    {
      "dateMentionedInArticle": "2025-02-06",
      "descriptionOfWhyDateIsRelevant": "The date when Defence Minister Guido Crosetto publicly disclosed the scam, stating he had received a call from a 'friend' and later from a 'General' claiming to represent his office."
    },
    {
      "dateMentionedInArticle": "2025-01-01",
      "descriptionOfWhyDateIsRelevant": "The beginning of a growing trend in deepfake scams, with reports of deepfake calls involving relatives in distress, escalating from $200 million to $347 million in losses between January and June 2025."
    },
    {
      "dateMentionedInArticle": "2025-07-01",
      "descriptionOfWhyDateIsRelevant": "The date of release of Resemble AI’s report showing that AI-generated child sexual abuse material has become industrialized and is a global law enforcement challenge."
    },
    {
      "dateMentionedInArticle": "2025-05-01",
      "descriptionOfWhyDateIsRelevant": "The date when US President Donald Trump signed legislation making it a federal crime to publish AI-generated intimate images of individuals without consent."
    },
    {
      "dateMentionedInArticle": "2025-09-24",
      "descriptionOfWhyDateIsRelevant": "The date when research from Queen Mary University of London was published in PLOS One, concluding that AI-generated voices are indistinguishable from real human voices in many cases."
    }
  ],
  "importantTimeframes": [
    {
      "approximateTimeFrameEnd": "2025",
      "approximateTimeFrameStart": "2025",
      "descriptionOfWhyTimeFrameIsRelevant": "The period during which AI-generated deepfake scams have significantly increased in frequency and sophistication, with global losses exceeding $547 million between January and June 2025."
    },
    {
      "approximateTimeFrameEnd": "2025",
      "approximateTimeFrameStart": "2023",
      "descriptionOfWhyTimeFrameIsRelevant": "The period during which the number of deepfakes shared online increased dramatically, from 500,000 in 2023 to an estimated 8 million by the end of 2025."
    }
  ],
  "keyTakeAways": [
    "AI-generated voices can now be indistinguishable from real human voices, especially when trained on large datasets of real voice recordings.",
    "A recent scam in Italy used AI to fake the voice of Defence Minister Guido Crosetto, tricking businessmen into sending money to a fraudulent account.",
    "The research from Queen Mary University of London found that 41% of AI-generated voices and 58% of voice clones were mistaken for real human voices, and participants rated AI voices as more trustworthy than real ones.",
    "AI deepfakes are being used to generate fake news, scam victims, and even sexual content involving real people, including industrialized production of AI-generated child sexual abuse material.",
    "Global financial losses from deepfake scams have risen sharply, with over $547 million lost worldwide between January and June 2025.",
    "In response, governments are taking action: the US banned the publication of AI-generated intimate images under federal law, and Australia banned a popular app used to create deepfake nudity.",
    "AI voice technology also has positive applications, such as helping people who have lost the ability to speak to regenerate their own voices."
  ],
  "namedEntities": [
    {
      "name": "Guido Crosetto",
      "whatIsThisEntity": "Defence Minister of Italy",
      "whyIsThisEntityRelevantToTheArticle": "He was the target of a deepfake voice scam where fraudsters used AI to mimic his voice to request money from businessmen."
    },
    {
      "name": "Giorgia Meloni",
      "whatIsThisEntity": "Prime Minister of Italy",
      "whyIsThisEntityRelevantToTheArticle": "Her government's actions in securing the release of journalist Cecilia Sala provided a context for the timing of the scam."
    },
    {
      "name": "Cecilia Sala",
      "whatIsThisEntity": "Italian journalist",
      "whyIsThisEntityRelevantToTheArticle": "Her release from imprisonment in Iran preceded the deepfake scam, adding context to the timeline of events in Italy."
    },
    {
      "name": "Massimo Moratti",
      "whatIsThisEntity": "Former owner of Inter Milan football club",
      "whyIsThisEntityRelevantToTheArticle": "He was one of the businessmen who sent money in response to the deepfake call and later filed a legal complaint."
    },
    {
      "name": "Giorgio Armani",
      "whatIsThisEntity": "Late Italian fashion designer",
      "whyIsThisEntityRelevantToTheArticle": "He was targeted in the AI voice scam, highlighting that even prominent public figures are vulnerable to such fraud."
    },
    {
      "name": "Patrizio Bertelli",
      "whatIsThisEntity": "Co-founder of Prada",
      "whyIsThisEntityRelevantToTheArticle": "He was one of the Italian entrepreneurs targeted in the deepfake scam."
    },
    {
      "name": "Nadine Lavan",
      "whatIsThisEntity": "Senior lecturer in psychology at Queen Mary University of London",
      "whyIsThisEntityRelevantToTheArticle": "She is a co-author of the research on AI voice realism and provided expert commentary on the technical and societal implications of deepfakes."
    },
    {
      "name": "Queen Mary University of London",
      "whatIsThisEntity": "University conducting AI voice research",
      "whyIsThisEntityRelevantToTheArticle": "The university conducted a study published in PLOS One showing that AI-generated voices are indistinguishable from real human voices in many cases."
    },
    {
      "name": "Resemble AI",
      "whatIsThisEntity": "California-based AI company",
      "whyIsThisEntityRelevantToTheArticle": "It reported that global losses from deepfake scams reached over $547 million between January and June 2025."
    },
    {
      "name": "DeepMedia",
      "whatIsThisEntity": "Company working on tools to detect synthetic media",
      "whyIsThisEntityRelevantToTheArticle": "It estimates that 8 million deepfakes will have been created and shared online by the end of 2025, showing a dramatic increase from 2023."
    },
    {
      "name": "Donald Trump",
      "whatIsThisEntity": "President of the United States",
      "whyIsThisEntityRelevantToTheArticle": "He signed a bill making it a federal crime to publish AI-generated intimate images without consent, indicating a policy response to AI-generated deepfakes."
    },
    {
      "name": "Australia",
      "whatIsThisEntity": "Government",
      "whyIsThisEntityRelevantToTheArticle": "The Australian government banned an application used to create deepfake nude images, showing a national policy response to AI-generated abuse."
    },
    {
      "name": "ElevenLabs",
      "whatIsThisEntity": "AI tool used in voice cloning research",
      "whyIsThisEntityRelevantToTheArticle": "It was used by researchers at Queen Mary University of London to generate AI voices in the study on voice realism."
    }
  ],
  "summaryOfNewsArticle": "A growing number of deepfake scams are exploiting advances in AI voice technology, with a recent case in Italy where fraudsters used AI to mimic the voice of Defence Minister Guido Crosetto, tricking businessmen into sending money. Research from Queen Mary University of London found that AI-generated voice clones are now indistinguishable from real human voices, with participants often rating them as more trustworthy. Global losses from such scams have surged to over $547 million between January and June 2025, and AI-generated deepfakes are being used to create fake news, manipulate public opinion, and generate illegal sexual content, including child exploitation material. In response, governments such as the United States and Australia have introduced new laws to criminalize the publication of AI-generated intimate images. While AI voice technology has beneficial applications—such as restoring speech for those who have lost their voice—its misuse poses serious threats to personal security, financial integrity, and social trust.",
  "tags": [
    "AI voice cloning",
    "deepfake scams",
    "fraud",
    "identity theft",
    "AI ethics",
    "government response",
    "voice technology",
    "security risks",
    "technology misuse",
    "international law",
    "public trust"
  ]
  ,
  "timeOfPublication": "14:46:58+00:00"
  ,
  "title": "AI now sounds more like us – should we be concerned?"
}