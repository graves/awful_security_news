{
  "category": "Science & Technology",
  "dateOfPublication": "2025-10-06",
  "importantDates": [
    {
      "dateMentionedInArticle": "2025-02-04",
      "descriptionOfWhyDateIsRelevant": "The date when the fraudulent call involving Defence Minister Guido Crosetto was reportedly received by the businessman, marking the start of the AI voice scam targeting Italian entrepreneurs."
    },
    {
      "dateMentionedInArticle": "2025-02-06",
      "descriptionOfWhyDateIsRelevant": "The date when Defence Minister Guido Crosetto publicly acknowledged receiving a fraudulent call from a purported 'friend' and a 'General', highlighting the public exposure of the deepfake scam."
    },
    {
      "dateMentionedInArticle": "2025-01-01",
      "descriptionOfWhyDateIsRelevant": "The start of a period during which deepfake scams began increasing globally, with reported losses rising from $200 million in the first quarter to $347 million in the second quarter of 2025."
    }
  ],
  "importantTimeframes": [
    {
      "approximateTimeFrameEnd": "2025-06-30",
      "approximateTimeFrameStart": "2025-01-01",
      "descriptionOfWhyTimeFrameIsRelevant": "The period between January and June 2025, during which global losses from deepfake scams rose to over $547.2 million, indicating a significant and growing trend in AI-powered fraud."
    }
  ],
  "keyTakeAways": [
    "AI-generated voices have become indistinguishable from real human voices, especially when trained on real recordings of individuals.",
    "Fake calls from deepfaked voices of public figures like Italy’s Defence Minister Guido Crosetto have successfully deceived wealthy entrepreneurs, leading to real financial losses.",
    "A 2025 study by Queen Mary University of London found that 41% of AI-generated voices and 58% of voice clones were mistaken for real human voices, with participants rating AI voices as more trustworthy than authentic ones.",
    "AI voice cloning can be used to generate convincing scams, including fake emergency calls from relatives, and is already being exploited globally, especially in financial fraud and identity theft.",
    "The rise of deepfakes has led to a surge in online synthetic media, with estimates of 8 million deepfakes created and shared by the end of 2025 — a dramatic increase from 500,000 in 2023.",
    "AI-generated child sexual abuse material is now being produced at scale, prompting legal responses in the US and Australia to ban or criminalize such content.",
    "AI voice technology also has beneficial applications, such as restoring speech for individuals with speech disabilities, demonstrating a dual nature of the technology."
  ],
  "namedEntities": [
    {
      "name": "Guido Crosetto",
      "whatIsThisEntity": "Defence Minister of Italy",
      "whyIsThisEntityRelevantToTheArticle": "The voice of Guido Crosetto was deepfaked in a scam that targeted wealthy Italian businessmen, who were deceived into sending money to a fraudulent account, raising concerns about AI-generated voice fraud."
    },
    {
      "name": "Giorgia Meloni",
      "whatIsThisEntity": "Prime Minister of Italy",
      "whyIsThisEntityRelevantToTheArticle": "Her recent role in securing the release of Italian journalist Cecilia Sala created a context where public figures are vulnerable to deepfake scams, increasing the risk of misinformation or fraud."
    },
    {
      "name": "Cecilia Sala",
      "whatIsThisEntity": "Italian journalist",
      "whyIsThisEntityRelevantToTheArticle": "Her imprisonment in Iran and subsequent release served as a backdrop to the timeline of events, highlighting how geopolitical tensions may increase public attention and vulnerability to scams involving prominent figures."
    },
    {
      "name": "Massimo Moratti",
      "whatIsThisEntity": "Former owner of Inter Milan football club",
      "whyIsThisEntityRelevantToTheArticle": "He was the only wealthy entrepreneur who sent money to a fraudulent account after being contacted by a deepfake voice, and has since filed a legal complaint, illustrating real-world financial impact and public concern."
    },
    {
      "name": "Giorgio Armani",
      "whatIsThisEntity": "Late Italian fashion designer",
      "whyIsThisEntityRelevantToTheArticle": "One of the prominent business figures targeted in the scam, demonstrating how high-profile individuals are susceptible to AI-powered fraud attempts."
    },
    {
      "name": "Patrizio Bertelli",
      "whatIsThisEntity": "Co-founder of Prada",
      "whyIsThisEntityRelevantToTheArticle": "Targeted in the AI voice scam, showing that even fashion industry leaders are at risk from sophisticated deepfake fraud."
    },
    {
      "name": "Nadine Lavan",
      "whatIsThisEntity": "Senior lecturer in psychology at Queen Mary University of London",
      "whyIsThisEntityRelevantToTheArticle": "She contributed to a key research study on AI voice realism, which found AI-generated voices are indistinguishable from real ones and rated more trustworthy, providing scientific credibility to the article's claims."
    },
    {
      "name": "Ian Goodfellow",
      "whatIsThisEntity": "Director of machine learning at Apple Special Projects Group",
      "whyIsThisEntityRelevantToTheArticle": "Coined the term 'deepfake' in 2014, establishing foundational terminology for understanding AI-generated audio and video deception."
    },
    {
      "name": "Resemble AI",
      "whatIsThisEntity": "California-based AI company",
      "whyIsThisEntityRelevantToTheArticle": "Provided data showing global losses from deepfake scams increased from $200 million to $347 million between Q1 and Q2 of 2025, illustrating the growing scale of AI-powered fraud."
    },
    {
      "name": "DeepMedia",
      "whatIsThisEntity": "Company working on synthetic media detection tools",
      "whyIsThisEntityRelevantToTheArticle": "Estimates that 8 million deepfakes will be shared online by end of 2025, highlighting the growing volume and spread of AI-generated deceptive content."
    },
    {
      "name": "United States",
      "whatIsThisEntity": "Country",
      "whyIsThisEntityRelevantToTheArticle": "Reported cases of deepfake scams involving relatives requesting money, and enacted federal legislation criminalizing the publication of AI-generated intimate images of individuals."
    },
    {
      "name": "Australia",
      "whatIsThisEntity": "Country",
      "whyIsThisEntityRelevantToTheArticle": "Announced a ban on an application used to generate deepfake nude images, showing global policy responses to AI-generated sexual content."
    },
    {
      "name": "ElevenLabs",
      "whatIsThisEntity": "AI voice generation tool",
      "whyIsThisEntityRelevantToTheArticle": "Used in the research study to generate AI voice samples, demonstrating the practical tools enabling realistic voice cloning and deepfaking."
    },
    {
      "name": "Queen Mary University of London",
      "whatIsThisEntity": "University",
      "whyIsThisEntityRelevantToTheArticle": "Conducted a peer-reviewed study published in PLOS One showing that AI-generated voices are indistinguishable from real voices in perception and trustworthiness."
    },
    {
      "name": "PLOS One",
      "whatIsThisEntity": "Scientific journal",
      "whyIsThisEntityRelevantToTheArticle": "Published the research on AI voice realism, providing scientific validation of the claims in the article about voice imitation and public perception."
    }
  ],
  "summaryOfNewsArticle": "AI-generated voice cloning has advanced to the point where fraudulent calls mimicking real public figures, such as Italy's Defence Minister Guido Crosetto, have successfully deceived wealthy entrepreneurs into transferring millions of euros. These scams, which began in February 2025, were identified by Crosetto after being contacted by business figures who made transfers based on fake calls from a 'General' or a purported friend. Research from Queen Mary University of London found that AI voice clones are indistinguishable from real human voices in perception and are often rated as more trustworthy. The global loss from such scams reached over $547 million between January and June 2025, with rising concerns about identity theft, misinformation, and the industrial production of AI-generated child sexual abuse material. While AI voice technology offers benefits such as restoring speech for people with disabilities, its misuse poses serious societal and legal challenges, prompting legal responses in the US and Australia to ban or criminalize deepfakes involving intimate content.",
  "tags": [
    "artificial intelligence",
    "deepfake",
    "voice cloning",
    "fraud",
    "identity theft",
    "AI voice scams",
    "Italy",
    "global security",
    "public trust",
    "AI ethics",
    "AI in crime",
    "technology risks",
    "digital deception"
  ]
  ,
  "timeOfPublication": "14:46:58+00:00"
  ,
  "title": "AI now sounds more like us – should we be concerned?"
}