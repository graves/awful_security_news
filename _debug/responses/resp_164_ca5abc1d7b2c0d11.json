{
  "category": "Science & Technology",
  "dateOfPublication": "2025-10-06",
  "importantDates": [
    {
      "dateMentionedInArticle": "2025-02-04",
      "descriptionOfWhyDateIsRelevant": "The date of the fraudulent call involving Defence Minister Guido Crosetto, which led to the scam targeting Italian businessmen."
    },
    {
      "dateMentionedInArticle": "2025-02-06",
      "descriptionOfWhyDateIsRelevant": "The date when Defence Minister Guido Crosetto publicly disclosed receiving a suspicious call from a purported entrepreneur, marking a key moment in exposing the AI-generated fraud."
    },
    {
      "dateMentionedInArticle": "2023-09-24",
      "descriptionOfWhyDateIsRelevant": "The date when research on AI voice realism was published in PLOS One, indicating scientific validation of AI-generated voices as indistinguishable from real ones."
    },
    {
      "dateMentionedInArticle": "2025-01-01",
      "descriptionOfWhyDateIsRelevant": "Beginning of the period during which deepfake scams globally reached $200 million in losses, signaling a rising trend in fraud."
    },
    {
      "dateMentionedInArticle": "2025-06-30",
      "descriptionOfWhyDateIsRelevant": "The projected end date by DeepMedia for the creation and sharing of deepfakes online, indicating a significant increase in synthetic media."
    }
  ],
  "importantTimeframes": [
    {
      "approximateTimeFrameEnd": "2025-06-30",
      "approximateTimeFrameStart": "2025-01-01",
      "descriptionOfWhyTimeFrameIsRelevant": "The period from January to June 2025 saw global deepfake scam losses rise from $200 million to $347 million, highlighting a growing threat of AI-powered fraud."
    },
    {
      "approximateTimeFrameEnd": "2025-09-30",
      "approximateTimeFrameStart": "2023-09-01",
      "descriptionOfWhyTimeFrameIsRelevant": "This time frame includes the research published in PLOS One, which demonstrated that AI-generated voices are now indistinguishable from real human voices, altering public trust dynamics."
    }
  ],
  "keyTakeAways": [
    "AI-generated voices are now indistinguishable from real human voices, especially when trained on real voice data, raising serious concerns about fraud and identity theft.",
    "The Italian scam involving fake Defence Minister Guido Crosetto’s voice, which targeted high-profile businessmen including Giorgio Armani and Patrizio Bertelli, illustrates real-world consequences of deepfake technology.",
    "AI voice cloning, powered by deep learning and NLP, can mimic accents, intonation, and even speech errors, making deepfakes highly convincing and trustworthy to listeners.",
    "A 2025 study by Queen Mary University of London found that 41% of AI-generated voices and 58% of voice clones were mistaken for real human voices, with participants often rating AI voices as more trustworthy.",
    "Global deepfake scams have surged, with over $547 million lost between January and June 2025, including fraudulent calls to relatives and financial exploitation.",
    "AI-generated deepfakes are being used to create sexual content, including child sexual abuse material, prompting legislative responses in the US and Australia.",
    "The use of AI to clone voices enables sophisticated scams, such as the one involving former Inter Milan owner Massimo Moratti, who transferred money based on a convincing fake call.",
    "Despite risks, AI voice technology has positive applications, such as helping people who have lost the ability to speak by restoring their own voices."
  ],
  "namedEntities": [
    {
      "name": "Guido Crosetto",
      "whatIsThisEntity": "Italian Defence Minister",
      "whyIsThisEntityRelevantToTheArticle": "He is the subject of a deepfake scam where fraudsters cloned his voice to request money from wealthy businessmen."
    },
    {
      "name": "Giorgia Meloni",
      "whatIsThisEntity": "Italian Prime Minister",
      "whyIsThisEntityRelevantToTheArticle": "Her political action in securing the release of journalist Cecilia Sala provided context for timing of the AI fraud scam."
    },
    {
      "name": "Cecilia Sala",
      "whatIsThisEntity": "Italian journalist",
      "whyIsThisEntityRelevantToTheArticle": "Her release in Iran preceded the fraud scam, linking the timing of the AI scam to a moment of heightened political sensitivity."
    },
    {
      "name": "Massimo Moratti",
      "whatIsThisEntity": "Former owner of Inter Milan football club",
      "whyIsThisEntityRelevantToTheArticle": "He is the only targeted businessman who actually sent money in the scam, and he filed a legal complaint after realizing the call was fraudulent."
    },
    {
      "name": "Giorgio Armani",
      "whatIsThisEntity": "Italian fashion designer",
      "whyIsThisEntityRelevantToTheArticle": "He was targeted in the AI voice scam, highlighting how high-profile individuals are vulnerable to such frauds."
    },
    {
      "name": "Patrizio Bertelli",
      "whatIsThisEntity": "Co-founder of Prada",
      "whyIsThisEntityRelevantToTheArticle": "He was among the prominent entrepreneurs targeted in the scam, illustrating the reach of AI-based fraud."
    },
    {
      "name": "Nadine Lavan",
      "whatIsThisEntity": "Senior lecturer in psychology at Queen Mary University of London",
      "whyIsThisEntityRelevantToTheArticle": "She is a lead researcher in the study on AI voice realism, providing scientific credibility to the claim that AI voices are now indistinguishable from real ones."
    },
    {
      "name": "Queen Mary University of London",
      "whatIsThisEntity": "University conducting AI voice research",
      "whyIsThisEntityRelevantToTheArticle": "The university led a study published in PLOS One that demonstrated AI-generated voices are now perceived as equally real as human voices."
    },
    {
      "name": "Resemble AI",
      "whatIsThisEntity": "California-based AI company",
      "whyIsThisEntityRelevantToTheArticle": "It reported global losses from deepfake scams, showing a growing trend in AI-powered fraud."
    },
    {
      "name": "ElevenLabs",
      "whatIsThisEntity": "AI voice generation tool",
      "whyIsThisEntityRelevantToTheArticle": "Used in the research to generate AI voice samples, demonstrating the technical tools behind voice cloning."
    },
    {
      "name": "DeepMedia",
      "whatIsThisEntity": "Company developing tools to detect synthetic media",
      "whyIsThisEntityRelevantToTheArticle": "Estimated that 8 million deepfakes will be created and shared online by end of 2025, showing the scale of synthetic media proliferation."
    },
    {
      "name": "Donald Trump",
      "whatIsThisEntity": "US President",
      "whyIsThisEntityRelevantToTheArticle": "He signed a federal law criminalizing the publication of AI-generated intimate images of people without consent, signaling policy response to AI deepfakes."
    },
    {
      "name": "Australian Government",
      "whatIsThisEntity": "Government of Australia",
      "whyIsThisEntityRelevantToTheArticle": "Announced a ban on an app used to create deepfake nude images, showing international policy efforts to combat AI-generated abuse."
    }
  ],
  "summaryOfNewsArticle": "A surge in AI-generated voice fraud has led to a major scam targeting wealthy Italian businessmen, where fraudsters used deepfake technology to mimic the voice of Defence Minister Guido Crosetto, requesting funds for a fake kidnapping of journalists. The scam, which occurred in February 2025, involved calls that sounded indistinguishable from real voices, with participants often perceiving AI voices as more trustworthy. Research from Queen Mary University of London confirms that AI voice clones are now nearly indistinguishable from real human voices, especially with British accents, and that people are increasingly misled into believing AI voices are authentic. The global trend shows over $547 million lost to deepfake scams between January and June 2025, with rising use of AI to generate sexual content and child abuse material. While AI voice technology offers benefits like restoring speech for the disabled, its misuse poses serious threats to personal identity, financial security, and public trust, prompting legal and policy responses in the US and Australia.",
  "tags": [
    "AI voice cloning",
    "deepfake scams",
    "voice fraud",
    "identity theft",
    "technology ethics",
    "financial crime",
    "AI safety",
    "digital deception",
    "political fraud",
    "international policy response"
  ]
  ,
  "timeOfPublication": "14:46:58Z"
  ,
  "title": "AI now sounds more like us – should we be concerned?"
}